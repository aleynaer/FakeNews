# FakeNews

Sahte Haber Tespiti projesi ile, toplanan haber manşetlerinin (başlıklarının) analizi yapılarak haberlerin niteliğini (gerçek yahut sahte) tespit etmek amaçlanmıştır.
Haber başlıkları gerçek ve sahte olmalarına göre iki farklı dosyada bulunmaktadır ve dosyadaki her bir satır bir haber manşetine denk gelmektedir. Bu dosyalardan haber başlıkları çekilerek nltk kütüphanesiyle metindeki her kelime token’laştırılmış, stop word’ler temizlenmiştir, kalan kelimeler stemming ve lemmatizing işlemlerine tabi tutulmuştur. Bu işlemler sonucu cümleler kelimelerine ayrıştırılmış, tek başına anlamı olmayan (edat,bağlaç vs) kelimeler veriden silinmiş, kalan kelimeler köklerine ve ilk biçimine çevrilmiştir.
Çalışmanın ilk aşamasında, veri seti cümle x tokenlar (kelimeler) matrisi ile temsil edilmek istenmiştir. Matrisin içi cümlelerin barındırdığı kelimelerin frekansı ile doldurulmuştur. Matrisin boyutunu azaltmak üzere, her kelime için IDF (inverse document frequency) hesaplanmış ve haberlerde fazlaca ortak kullanılan kelimeer veri setinden silinmiştir. Sonuç olarak 3266 x 3698 ‘lik haber başlığı x kelime matrisi oluşturulmuştur. Elde edilen matris üzerinde işlem ve modelleme yapmanıın vakit olarak dezavantajlı olmasından dolayı bu yöntemden vazgeçilmiştir.
Projeye devam edilen yöntemde, gerçek ve sahte haberler için bu işlemler ayrı ayrı yapılmış ve elde edilen kelimeler iki farklı listede tutulmuştur, bunlar sahteKelime listesi ve gerçekKelime listesi olarak isimlendirilmiştir.
Haber başlıkları, oluştukları kelimelerin sahteKelime ve gerçekKelime listelerinde bulunma sıklığına göre işleme tabi tutulmuştur. Hesaplama sonucu mevcut haberin bulundurduğu sahte ve gerçek kelime sayısı o haberin uzunluğuna bölünerek normalize edilmiş, haber başlığının yüzde kaçının o listeye ait olduğu hesaplanmıştır.
Yapılan hesaplamala ile birlikte, veri seti modellemeye hazırlanmıştır. KNN, Decision Tree ve Naive Bayes algoritmalarıyla tahminleme işlemi gerçekleştirilmiştir. Kullanılan algoritmalar için, veri seti yüzde 70 train, 15 test ve 15 validation olmak üzere üç parçaya bölünmüştür. Algoritmaların parametreleri optimize edilerek ve k-fold cross-validation yöntemi kullanılarak model başarısı yükseltimek istenmiştir.
